{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR+fJjvuBwEOrAUZImi/Vm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YaswanthPothineni/test/blob/main/Text_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VAyKSvvfATG-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = '/content/E.M.Forster.txt'"
      ],
      "metadata": {
        "id": "9ybcx7PMAtFA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'r').read()"
      ],
      "metadata": {
        "id": "v1NyDLe4CDqy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBoQecFQCGQ5",
        "outputId": "206957c5-8395-49a9-9c96-3adb6c9605da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter I\n",
            "The Bertolini\n",
            "\n",
            "\n",
            "“The Signora had no business to do it,” said Miss Bartlett, “no\n",
            "business at all. She promised us south rooms with a view close\n",
            "together, instead of which here are north rooms, looking into a\n",
            "courtyard, and a long way apart. Oh, Lucy!”\n",
            "\n",
            "“And a Cockney, besides!” said Lucy, who had been further saddened by\n",
            "the Signora’s unexpected accent. “It might be London.” She looked at\n",
            "the two rows of English people who were sitting at the table; at the\n",
            "row of white bottles of water \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unique Characters**"
      ],
      "metadata": {
        "id": "2y4AxprHCPWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "unique = sorted(set(text))\n",
        "print(unique)\n",
        "len(unique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLCp9OlzCYsy",
        "outputId": "ad91f9f8-4bab-457a-ba06-aaabaf39743e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '£', 'à', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ì', 'í', 'ó', 'ö', 'ù', 'Œ', 'œ', '—', '‘', '’', '“', '”']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text** **Processing**"
      ],
      "metadata": {
        "id": "LTwuwEPYCmsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Vectorization :\n",
        "Knowing that a neural network cannot process raw string data, we must give each character a numerical value. Let's make two dictionaries that can translate from character to numeric index and vice versa.**"
      ],
      "metadata": {
        "id": "yGpuszdUCy4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind = {u:i for i, u in enumerate(unique)}"
      ],
      "metadata": {
        "id": "R1_FMRJFChxm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbsOnG7iDR2B",
        "outputId": "a5ec2b3f-77bd-44f2-9c17-92d1aab8dcb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " '*': 8,\n",
              " ',': 9,\n",
              " '-': 10,\n",
              " '.': 11,\n",
              " '0': 12,\n",
              " '1': 13,\n",
              " '2': 14,\n",
              " '3': 15,\n",
              " '4': 16,\n",
              " '5': 17,\n",
              " '6': 18,\n",
              " '7': 19,\n",
              " '8': 20,\n",
              " '9': 21,\n",
              " ':': 22,\n",
              " ';': 23,\n",
              " '=': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '£': 82,\n",
              " 'à': 83,\n",
              " 'â': 84,\n",
              " 'ä': 85,\n",
              " 'æ': 86,\n",
              " 'ç': 87,\n",
              " 'è': 88,\n",
              " 'é': 89,\n",
              " 'ê': 90,\n",
              " 'ì': 91,\n",
              " 'í': 92,\n",
              " 'ó': 93,\n",
              " 'ö': 94,\n",
              " 'ù': 95,\n",
              " 'Œ': 96,\n",
              " 'œ': 97,\n",
              " '—': 98,\n",
              " '‘': 99,\n",
              " '’': 100,\n",
              " '“': 101,\n",
              " '”': 102}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char = np.array(unique) # Index to character"
      ],
      "metadata": {
        "id": "N8MA0tF5DVOU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxnETg9zDcJm",
        "outputId": "a7a8a6e1-1c94-4a7f-b398-c600ea1b626d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0',\n",
              "       '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '£', 'à', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê',\n",
              "       'ì', 'í', 'ó', 'ö', 'ù', 'Œ', 'œ', '—', '‘', '’', '“', '”'],\n",
              "      dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "metadata": {
        "id": "V1UVDV2mDiOD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMB8K6UwDmGm",
        "outputId": "995df075-a5b8-4b6d-e71e-2e51d8f0515e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28, 63, 56, ...,  1,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a mapping that we can use to switch between characters and numbers.\n"
      ],
      "metadata": {
        "id": "9dbtM9b4Dypa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = text[:20]\n",
        "sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "luOX37XmDodB",
        "outputId": "505b404f-c5cc-4e3c-c6c7-95aefd47b4cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chapter I\\nThe Bertol'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cv4u-LWD3oK",
        "outputId": "fe7ac419-d7a5-48df-aa7f-fa81183fee6c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28, 63, 56, 71, 75, 60, 73,  1, 34,  0, 45, 63, 60,  1, 27, 60, 73,\n",
              "       75, 70, 67])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Batches**"
      ],
      "metadata": {
        "id": "f7OYVSw5D979"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, our goal is to have the model predict the following character with the best probability given a historical series of characters. The length of the historical series is up to the user. A sequence that is too short leaves us with insufficient information (e.g., given the letter \"a,\" what is the next character), whereas a sequence that is too long causes training to take too long and is likely to overfit to sequence characters that are irrelevant to characters further out. Although there is no ideal sequence length, you should take into account the text itself, the length of typical phrases, and a good understanding of the letters and words that are related to one another.\n"
      ],
      "metadata": {
        "id": "zuMFB3x0EPCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8zC6mk8D6PE",
        "outputId": "5bebbbb9-d126-482b-f9d6-3506841e9823"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter I\n",
            "The Bertolini\n",
            "\n",
            "\n",
            "“The Signora had no business to do it,” said Miss Bartlett, “no\n",
            "business at all. She promised us south rooms with a view close\n",
            "together, instead of which here are north rooms, looking into a\n",
            "courtyard, and a long way apart. Oh, Lucy!”\n",
            "\n",
            "“And a Cockney, besides!” said Lucy, who had been further saddened by\n",
            "the Signora’s unexpected accent. “It might be London.” She looked at\n",
            "the two rows of English people who were sitting at the table; at the\n",
            "row of white bottles of water \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza_line= 'The Signora had no business to do it,” said Miss Bartlett, “no business at all. She promised us south rooms with a view close together, instead of which here are north rooms, looking into a courtyard, and a long way apart. Oh, Lucy'"
      ],
      "metadata": {
        "id": "pANzJ_rxEjDl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(stanza_line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrXW2qMYE4oQ",
        "outputId": "8bcf03d9-c8ce-4dd7-c82a-3ac978c90873"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, on an average we can take length of line as 200"
      ],
      "metadata": {
        "id": "noQTQATOFEzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "zDQyxBTkFMVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 200"
      ],
      "metadata": {
        "id": "h0T1GiJ_E6-1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq = len(text)//(seq_len+1)"
      ],
      "metadata": {
        "id": "n3bbNOdQFbfg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q555vgjiFds5",
        "outputId": "58fb19ba-d2fe-45c8-d85f-c22655483bc3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11857"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These individual character requests are transformed into sequences we can input as a batch using the batch method. Because zero indexing is used, we use seq_len+1. What drop_remainder signifies is as follows:\n",
        "\n",
        "(Optional) Drop remaining items. a tf.bool scalar tf.Tensor that indicates whether the previous batch should be eliminated if it contains less elements than batch_size; the default approach is to keep the larger batch.\n",
        "\n"
      ],
      "metadata": {
        "id": "EDLhA_JpGWEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "\n",
        "for i in char_dataset.take(500):\n",
        "     print(ind_to_char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0mCwW0vFflX",
        "outputId": "c61c0ba1-8500-4863-8a4b-0388b8ef8183"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C\n",
            "h\n",
            "a\n",
            "p\n",
            "t\n",
            "e\n",
            "r\n",
            " \n",
            "I\n",
            "\n",
            "\n",
            "T\n",
            "h\n",
            "e\n",
            " \n",
            "B\n",
            "e\n",
            "r\n",
            "t\n",
            "o\n",
            "l\n",
            "i\n",
            "n\n",
            "i\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“\n",
            "T\n",
            "h\n",
            "e\n",
            " \n",
            "S\n",
            "i\n",
            "g\n",
            "n\n",
            "o\n",
            "r\n",
            "a\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "n\n",
            "o\n",
            " \n",
            "b\n",
            "u\n",
            "s\n",
            "i\n",
            "n\n",
            "e\n",
            "s\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "d\n",
            "o\n",
            " \n",
            "i\n",
            "t\n",
            ",\n",
            "”\n",
            " \n",
            "s\n",
            "a\n",
            "i\n",
            "d\n",
            " \n",
            "M\n",
            "i\n",
            "s\n",
            "s\n",
            " \n",
            "B\n",
            "a\n",
            "r\n",
            "t\n",
            "l\n",
            "e\n",
            "t\n",
            "t\n",
            ",\n",
            " \n",
            "“\n",
            "n\n",
            "o\n",
            "\n",
            "\n",
            "b\n",
            "u\n",
            "s\n",
            "i\n",
            "n\n",
            "e\n",
            "s\n",
            "s\n",
            " \n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "l\n",
            "l\n",
            ".\n",
            " \n",
            "S\n",
            "h\n",
            "e\n",
            " \n",
            "p\n",
            "r\n",
            "o\n",
            "m\n",
            "i\n",
            "s\n",
            "e\n",
            "d\n",
            " \n",
            "u\n",
            "s\n",
            " \n",
            "s\n",
            "o\n",
            "u\n",
            "t\n",
            "h\n",
            " \n",
            "r\n",
            "o\n",
            "o\n",
            "m\n",
            "s\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "a\n",
            " \n",
            "v\n",
            "i\n",
            "e\n",
            "w\n",
            " \n",
            "c\n",
            "l\n",
            "o\n",
            "s\n",
            "e\n",
            "\n",
            "\n",
            "t\n",
            "o\n",
            "g\n",
            "e\n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            ",\n",
            " \n",
            "i\n",
            "n\n",
            "s\n",
            "t\n",
            "e\n",
            "a\n",
            "d\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "w\n",
            "h\n",
            "i\n",
            "c\n",
            "h\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "r\n",
            "e\n",
            " \n",
            "n\n",
            "o\n",
            "r\n",
            "t\n",
            "h\n",
            " \n",
            "r\n",
            "o\n",
            "o\n",
            "m\n",
            "s\n",
            ",\n",
            " \n",
            "l\n",
            "o\n",
            "o\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "i\n",
            "n\n",
            "t\n",
            "o\n",
            " \n",
            "a\n",
            "\n",
            "\n",
            "c\n",
            "o\n",
            "u\n",
            "r\n",
            "t\n",
            "y\n",
            "a\n",
            "r\n",
            "d\n",
            ",\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "a\n",
            " \n",
            "l\n",
            "o\n",
            "n\n",
            "g\n",
            " \n",
            "w\n",
            "a\n",
            "y\n",
            " \n",
            "a\n",
            "p\n",
            "a\n",
            "r\n",
            "t\n",
            ".\n",
            " \n",
            "O\n",
            "h\n",
            ",\n",
            " \n",
            "L\n",
            "u\n",
            "c\n",
            "y\n",
            "!\n",
            "”\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“\n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "a\n",
            " \n",
            "C\n",
            "o\n",
            "c\n",
            "k\n",
            "n\n",
            "e\n",
            "y\n",
            ",\n",
            " \n",
            "b\n",
            "e\n",
            "s\n",
            "i\n",
            "d\n",
            "e\n",
            "s\n",
            "!\n",
            "”\n",
            " \n",
            "s\n",
            "a\n",
            "i\n",
            "d\n",
            " \n",
            "L\n",
            "u\n",
            "c\n",
            "y\n",
            ",\n",
            " \n",
            "w\n",
            "h\n",
            "o\n",
            " \n",
            "h\n",
            "a\n",
            "d\n",
            " \n",
            "b\n",
            "e\n",
            "e\n",
            "n\n",
            " \n",
            "f\n",
            "u\n",
            "r\n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "a\n",
            "d\n",
            "d\n",
            "e\n",
            "n\n",
            "e\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            "\n",
            "\n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "S\n",
            "i\n",
            "g\n",
            "n\n",
            "o\n",
            "r\n",
            "a\n",
            "’\n",
            "s\n",
            " \n",
            "u\n",
            "n\n",
            "e\n",
            "x\n",
            "p\n",
            "e\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "a\n",
            "c\n",
            "c\n",
            "e\n",
            "n\n",
            "t\n",
            ".\n",
            " \n",
            "“\n",
            "I\n",
            "t\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            " \n",
            "L\n",
            "o\n",
            "n\n",
            "d\n",
            "o\n",
            "n\n",
            ".\n",
            "”\n",
            " \n",
            "S\n",
            "h\n",
            "e\n",
            " \n",
            "l\n",
            "o\n",
            "o\n",
            "k\n",
            "e\n",
            "d\n",
            " \n",
            "a\n",
            "t\n",
            "\n",
            "\n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "t\n",
            "w\n",
            "o\n",
            " \n",
            "r\n",
            "o\n",
            "w\n",
            "s\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "E\n",
            "n\n",
            "g\n",
            "l\n",
            "i\n",
            "s\n",
            "h\n",
            " \n",
            "p\n",
            "e\n",
            "o\n",
            "p\n",
            "l\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "o\n",
            " \n",
            "w\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "s\n",
            "i\n",
            "t\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "t\n",
            "a\n",
            "b\n",
            "l\n",
            "e\n",
            ";\n",
            " \n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "\n",
            "\n",
            "r\n",
            "o\n",
            "w\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "w\n",
            "h\n",
            "i\n",
            "t\n",
            "e\n",
            " \n",
            "b\n",
            "o\n",
            "t\n",
            "t\n",
            "l\n",
            "e\n",
            "s\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "w\n",
            "a\n",
            "t\n",
            "e\n",
            "r\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "60KYMLt4Gc8t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have our sequences, and to produce our target text sequences, we will carry out the following procedures for each of them:\n",
        "\n",
        "1) Take the input text flow.\n",
        "2) Shift the input text sequence one step ahead before assigning the target text sequence.\n",
        "3) Combine them into a tuple.\n"
      ],
      "metadata": {
        "id": "Fes16PRMG5z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt"
      ],
      "metadata": {
        "id": "A7qJ7p3kGr2n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = sequences.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "NK6LjHQmHEnX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_txt, target_txt in  data.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    # There is an extra whitespace!\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PntCr7ldHKMY",
        "outputId": "106bfee4-03b5-47c2-fd99-7f86e1e2690a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 28  63  56  71  75  60  73   1  34   0  45  63  60   1  27  60  73  75\n",
            "  70  67  64  69  64   0   0   0 101  45  63  60   1  44  64  62  69  70\n",
            "  73  56   1  63  56  59   1  69  70   1  57  76  74  64  69  60  74  74\n",
            "   1  75  70   1  59  70   1  64  75   9 102   1  74  56  64  59   1  38\n",
            "  64  74  74   1  27  56  73  75  67  60  75  75   9   1 101  69  70   0\n",
            "  57  76  74  64  69  60  74  74   1  56  75   1  56  67  67  11   1  44\n",
            "  63  60   1  71  73  70  68  64  74  60  59   1  76  74   1  74  70  76\n",
            "  75  63   1  73  70  70  68  74   1  78  64  75  63   1  56   1  77  64\n",
            "  60  78   1  58  67  70  74  60   0  75  70  62  60  75  63  60  73   9\n",
            "   1  64  69  74  75  60  56  59   1  70  61   1  78  63  64  58  63   1\n",
            "  63  60  73  60   1  56  73  60   1  69  70  73  75  63   1  73  70  70\n",
            "  68  74]\n",
            "Chapter I\n",
            "The Bertolini\n",
            "\n",
            "\n",
            "“The Signora had no business to do it,” said Miss Bartlett, “no\n",
            "business at all. She promised us south rooms with a view close\n",
            "together, instead of which here are north rooms\n",
            "\n",
            "\n",
            "[ 63  56  71  75  60  73   1  34   0  45  63  60   1  27  60  73  75  70\n",
            "  67  64  69  64   0   0   0 101  45  63  60   1  44  64  62  69  70  73\n",
            "  56   1  63  56  59   1  69  70   1  57  76  74  64  69  60  74  74   1\n",
            "  75  70   1  59  70   1  64  75   9 102   1  74  56  64  59   1  38  64\n",
            "  74  74   1  27  56  73  75  67  60  75  75   9   1 101  69  70   0  57\n",
            "  76  74  64  69  60  74  74   1  56  75   1  56  67  67  11   1  44  63\n",
            "  60   1  71  73  70  68  64  74  60  59   1  76  74   1  74  70  76  75\n",
            "  63   1  73  70  70  68  74   1  78  64  75  63   1  56   1  77  64  60\n",
            "  78   1  58  67  70  74  60   0  75  70  62  60  75  63  60  73   9   1\n",
            "  64  69  74  75  60  56  59   1  70  61   1  78  63  64  58  63   1  63\n",
            "  60  73  60   1  56  73  60   1  69  70  73  75  63   1  73  70  70  68\n",
            "  74   9]\n",
            "hapter I\n",
            "The Bertolini\n",
            "\n",
            "\n",
            "“The Signora had no business to do it,” said Miss Bartlett, “no\n",
            "business at all. She promised us south rooms with a view close\n",
            "together, instead of which here are north rooms,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating training batches**"
      ],
      "metadata": {
        "id": "tKEywUIsHUAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to shuffle these sequences into a random order so the model doesn't overfit to any one area of the text and can instead generate characters given any seed text. Now that we have the actual sequences, we will create the batches.\n"
      ],
      "metadata": {
        "id": "R-VZeBMDHbQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = data.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "gBnth4iQHN_H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly-kCTM3HgOB",
        "outputId": "4a49cb3c-6f6d-4561-fc07-643446c3acff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 200), dtype=tf.int64, name=None), TensorSpec(shape=(128, 200), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Model**"
      ],
      "metadata": {
        "id": "SxqHrQ-DHlqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With two LSTM layers and an initial embedding layer, our LSTM-based model will also have a few more properties. The DeepMoji, whose original source code can be accessed here, served as the inspiration for this model's architecture.\n",
        "\n",
        "The input layer will be the embedding layer, which functions as a sort of lookup table that converts each character's numerical indices into a vector with a \"embedding dim\" number of dimensions. As you can expect, the training becomes more difficult as the embedding size increases. This concept is comparable to word2vec, which maps words to an n-dimensional space. Results that have been embedded before being fed directly into the LSTM are typically more realistic.\n"
      ],
      "metadata": {
        "id": "oroQCKAxHtEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(unique)\n",
        "\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ],
      "metadata": {
        "id": "vALIIeR2HiEZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ],
      "metadata": {
        "id": "SaiI6eOAH7sN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up Loss Function**"
      ],
      "metadata": {
        "id": "x6NEBS0VIC_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We may import sparse categorical crossentropy from Keras to calculate our loss. Additionally, we'll set this to logits=True.\n"
      ],
      "metadata": {
        "id": "jD-cvEMCIKdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "xXPHpb3ZIASt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "metadata": {
        "id": "POpWdGzTIQ04"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    # Final Dense Layer to Predict\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "    return model"
      ],
      "metadata": {
        "id": "uMADJeU0IbEp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embed_dim=embed_dim,\n",
        "  rnn_neurons=rnn_neurons,\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "OcaIPUr2JH8x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iddqk0gJJqy",
        "outputId": "1e15553a-26ff-4586-e43b-b528a92256a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           6592      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 103)          105781    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,473,549\n",
            "Trainable params: 3,473,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "4wqkyDz-JPm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we invest too much time in training, let's make sure our model is happy with everything. To verify that the model now predicts random characters devoid of any training, let's pass in a batch.\n",
        "\n"
      ],
      "metadata": {
        "id": "oW8U71tUJW7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ePaoKxJMrz",
        "outputId": "fd779c25-1a75-4eac-a436-72427b901718"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 200, 103)  <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEw_InntJhoK",
        "outputId": "5a6a4983-6a6a-4d89-a86c-8581f4a30bef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 200, 103), dtype=float32, numpy=\n",
              "array([[[-8.02959315e-04,  1.48999956e-04, -2.72493437e-03, ...,\n",
              "          2.37293192e-03, -1.63633842e-03, -2.77730078e-03],\n",
              "        [ 3.52706201e-03, -3.80177773e-03, -3.98030039e-03, ...,\n",
              "         -1.37914467e-04, -3.49699170e-03, -6.56784652e-03],\n",
              "        [ 3.31148366e-03, -1.59712532e-03, -6.98893055e-05, ...,\n",
              "         -4.33085300e-03,  1.85002154e-03, -5.29798772e-03],\n",
              "        ...,\n",
              "        [-3.95849440e-03,  7.81338848e-03,  6.80229161e-03, ...,\n",
              "         -1.95682910e-03, -1.15595162e-02, -8.90797656e-03],\n",
              "        [-5.74252149e-03, -1.64745070e-04,  4.65748319e-03, ...,\n",
              "         -1.02727041e-02, -4.12336364e-03, -1.05308602e-02],\n",
              "        [-4.63347416e-03, -5.98690519e-03,  1.03861084e-02, ...,\n",
              "         -1.09854760e-02, -1.75718020e-03, -2.37987866e-03]],\n",
              "\n",
              "       [[-2.24520918e-03,  2.46209581e-03, -1.56388478e-03, ...,\n",
              "         -3.19403992e-03, -5.13293501e-03,  4.70929965e-03],\n",
              "        [-8.08521081e-03, -1.20279146e-03, -3.90003552e-03, ...,\n",
              "          1.54914882e-03, -5.09286160e-03,  3.85054084e-03],\n",
              "        [-3.55700846e-03, -1.84181635e-03, -5.00641717e-03, ...,\n",
              "          6.62384601e-03, -8.27825163e-03,  6.94649806e-03],\n",
              "        ...,\n",
              "        [-3.90153076e-03, -7.99492747e-03, -8.54175724e-03, ...,\n",
              "          5.74392313e-03,  4.75972798e-03,  2.90955743e-03],\n",
              "        [ 9.70763736e-04, -1.66115048e-03, -7.56571721e-03, ...,\n",
              "          1.07169915e-02,  8.75375886e-03, -1.41465419e-03],\n",
              "        [-3.30690440e-04, -3.90892325e-04, -6.83982670e-03, ...,\n",
              "          7.60185486e-03,  3.08035640e-03, -3.50421458e-03]],\n",
              "\n",
              "       [[-3.70022771e-03, -6.68583112e-03,  1.37513666e-03, ...,\n",
              "         -4.78871213e-03, -4.54168941e-04,  3.35792219e-03],\n",
              "        [ 3.42105981e-04, -8.19584914e-03, -1.89674424e-03, ...,\n",
              "         -5.03671216e-03, -2.91670696e-03, -3.55084683e-03],\n",
              "        [ 6.67887565e-04, -4.25494416e-03,  1.17127155e-03, ...,\n",
              "         -7.55859539e-03,  2.20810506e-03, -3.70683917e-03],\n",
              "        ...,\n",
              "        [ 3.79472331e-04, -2.85193091e-03,  1.43005906e-04, ...,\n",
              "         -7.96121359e-03,  3.68037983e-03, -4.61420976e-03],\n",
              "        [ 3.87898716e-03, -5.38405171e-03, -2.71849637e-03, ...,\n",
              "         -5.30827045e-03, -2.04051263e-04, -8.10032990e-03],\n",
              "        [ 3.09359119e-03, -1.73429656e-03, -1.06435444e-03, ...,\n",
              "         -1.80697488e-03,  1.61422091e-03, -8.06798041e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.79437548e-03, -3.15022189e-04,  1.70421891e-03, ...,\n",
              "         -5.88312093e-03,  3.55955842e-03, -2.32883054e-03],\n",
              "        [-8.39389919e-04,  7.04050204e-03,  6.74746418e-03, ...,\n",
              "         -1.47309678e-03, -9.62789543e-03, -9.37930401e-03],\n",
              "        [-4.72720421e-04,  3.26745049e-03,  1.22954615e-03, ...,\n",
              "          1.37683819e-03, -6.34651585e-03, -8.76568630e-03],\n",
              "        ...,\n",
              "        [-1.38833537e-03,  5.39105199e-03,  5.09879319e-03, ...,\n",
              "          1.62428827e-03, -1.15652597e-02, -1.06220869e-02],\n",
              "        [-4.37250175e-03, -7.81870156e-04,  4.09428403e-03, ...,\n",
              "         -8.10090918e-03, -4.10665711e-03, -1.12457266e-02],\n",
              "        [ 3.42686451e-03,  2.87558092e-03,  4.92758350e-03, ...,\n",
              "         -1.33524428e-03, -1.49663351e-03, -1.14585494e-03]],\n",
              "\n",
              "       [[-8.02959315e-04,  1.48999956e-04, -2.72493437e-03, ...,\n",
              "          2.37293192e-03, -1.63633842e-03, -2.77730078e-03],\n",
              "        [-3.85648687e-03, -5.88518986e-03,  3.49769252e-04, ...,\n",
              "         -2.89503182e-03, -1.34591106e-03,  2.26208032e-03],\n",
              "        [ 4.87622310e-04, -7.55450688e-03, -2.35012197e-03, ...,\n",
              "         -3.70654231e-03, -3.47220455e-03, -3.95225780e-03],\n",
              "        ...,\n",
              "        [ 1.70717831e-03, -5.79583691e-03, -9.31025855e-03, ...,\n",
              "          8.59567989e-03,  4.98274015e-03, -9.95831098e-04],\n",
              "        [-3.17029399e-03, -9.40902252e-03, -3.02698277e-03, ...,\n",
              "         -3.64018604e-04,  1.94593309e-03,  3.56174260e-03],\n",
              "        [-1.12178421e-03, -4.78439732e-03, -5.65359427e-04, ...,\n",
              "         -1.15731987e-03,  2.44603632e-03, -1.40473561e-03]],\n",
              "\n",
              "       [[ 1.05502526e-03, -9.02181666e-04,  1.04818691e-03, ...,\n",
              "          7.23497942e-03,  3.28731025e-03,  1.97758712e-03],\n",
              "        [-2.06656358e-03,  2.49059801e-03,  4.42280713e-03, ...,\n",
              "         -1.30388211e-03,  1.53836806e-03, -5.68067608e-03],\n",
              "        [ 2.03840155e-03, -3.32734594e-03, -7.90329301e-04, ...,\n",
              "         -2.77847401e-03, -1.87713280e-03, -8.83288123e-03],\n",
              "        ...,\n",
              "        [ 2.46464246e-04, -8.13196972e-03, -1.89425412e-03, ...,\n",
              "         -4.18837834e-03, -6.26291428e-03, -4.13402263e-03],\n",
              "        [-5.12990635e-03, -5.74774295e-03, -1.87882048e-03, ...,\n",
              "         -6.98422641e-03, -1.22365693e-03, -1.23960059e-03],\n",
              "        [-3.72301205e-03, -5.02624596e-03, -6.38778834e-03, ...,\n",
              "          4.64762235e-03,  6.65574335e-03,  1.23613689e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "metadata": {
        "id": "NcG7cp5KJlIm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAQfB8MyJn9L",
        "outputId": "0a511faf-fd53-4b4a-c9ec-aa04f25a7d6d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(200, 1), dtype=int64, numpy=\n",
              "array([[100],\n",
              "       [ 84],\n",
              "       [ 90],\n",
              "       [  8],\n",
              "       [ 84],\n",
              "       [ 69],\n",
              "       [ 43],\n",
              "       [ 25],\n",
              "       [  4],\n",
              "       [ 79],\n",
              "       [ 31],\n",
              "       [ 15],\n",
              "       [ 18],\n",
              "       [ 99],\n",
              "       [ 61],\n",
              "       [ 34],\n",
              "       [ 94],\n",
              "       [ 91],\n",
              "       [ 76],\n",
              "       [ 98],\n",
              "       [ 39],\n",
              "       [ 56],\n",
              "       [ 83],\n",
              "       [ 97],\n",
              "       [ 36],\n",
              "       [ 58],\n",
              "       [101],\n",
              "       [ 40],\n",
              "       [ 53],\n",
              "       [ 66],\n",
              "       [  1],\n",
              "       [  1],\n",
              "       [ 42],\n",
              "       [ 88],\n",
              "       [ 25],\n",
              "       [ 60],\n",
              "       [ 78],\n",
              "       [ 26],\n",
              "       [ 94],\n",
              "       [ 96],\n",
              "       [ 29],\n",
              "       [ 38],\n",
              "       [ 31],\n",
              "       [ 51],\n",
              "       [  0],\n",
              "       [ 70],\n",
              "       [ 55],\n",
              "       [ 95],\n",
              "       [ 66],\n",
              "       [ 46],\n",
              "       [ 45],\n",
              "       [101],\n",
              "       [ 46],\n",
              "       [ 72],\n",
              "       [  4],\n",
              "       [  8],\n",
              "       [ 90],\n",
              "       [ 94],\n",
              "       [ 69],\n",
              "       [ 69],\n",
              "       [ 13],\n",
              "       [ 91],\n",
              "       [ 23],\n",
              "       [ 24],\n",
              "       [  3],\n",
              "       [ 49],\n",
              "       [  4],\n",
              "       [ 28],\n",
              "       [ 56],\n",
              "       [  0],\n",
              "       [ 27],\n",
              "       [ 41],\n",
              "       [ 75],\n",
              "       [ 63],\n",
              "       [ 15],\n",
              "       [  5],\n",
              "       [  3],\n",
              "       [ 93],\n",
              "       [ 97],\n",
              "       [ 74],\n",
              "       [ 12],\n",
              "       [ 83],\n",
              "       [ 42],\n",
              "       [ 44],\n",
              "       [ 99],\n",
              "       [ 53],\n",
              "       [ 82],\n",
              "       [ 18],\n",
              "       [  3],\n",
              "       [ 86],\n",
              "       [ 99],\n",
              "       [ 78],\n",
              "       [102],\n",
              "       [ 92],\n",
              "       [ 97],\n",
              "       [ 12],\n",
              "       [ 71],\n",
              "       [ 92],\n",
              "       [ 47],\n",
              "       [ 59],\n",
              "       [ 33],\n",
              "       [ 12],\n",
              "       [ 90],\n",
              "       [ 11],\n",
              "       [  2],\n",
              "       [ 23],\n",
              "       [ 62],\n",
              "       [  8],\n",
              "       [ 38],\n",
              "       [ 32],\n",
              "       [ 10],\n",
              "       [101],\n",
              "       [ 86],\n",
              "       [ 47],\n",
              "       [ 49],\n",
              "       [  6],\n",
              "       [ 70],\n",
              "       [ 68],\n",
              "       [ 25],\n",
              "       [ 38],\n",
              "       [ 21],\n",
              "       [ 37],\n",
              "       [  0],\n",
              "       [ 90],\n",
              "       [ 24],\n",
              "       [ 88],\n",
              "       [ 68],\n",
              "       [ 87],\n",
              "       [ 82],\n",
              "       [ 86],\n",
              "       [ 70],\n",
              "       [ 98],\n",
              "       [ 30],\n",
              "       [ 68],\n",
              "       [ 28],\n",
              "       [ 19],\n",
              "       [ 83],\n",
              "       [ 11],\n",
              "       [ 67],\n",
              "       [ 56],\n",
              "       [ 70],\n",
              "       [ 33],\n",
              "       [ 33],\n",
              "       [ 60],\n",
              "       [ 91],\n",
              "       [ 42],\n",
              "       [ 37],\n",
              "       [ 43],\n",
              "       [ 59],\n",
              "       [ 10],\n",
              "       [ 11],\n",
              "       [ 78],\n",
              "       [ 13],\n",
              "       [  4],\n",
              "       [  6],\n",
              "       [ 82],\n",
              "       [  1],\n",
              "       [ 21],\n",
              "       [ 41],\n",
              "       [ 48],\n",
              "       [ 78],\n",
              "       [ 39],\n",
              "       [ 69],\n",
              "       [ 22],\n",
              "       [ 18],\n",
              "       [ 36],\n",
              "       [ 58],\n",
              "       [ 93],\n",
              "       [ 45],\n",
              "       [ 91],\n",
              "       [ 48],\n",
              "       [ 52],\n",
              "       [ 99],\n",
              "       [ 49],\n",
              "       [ 89],\n",
              "       [ 39],\n",
              "       [ 75],\n",
              "       [ 22],\n",
              "       [ 57],\n",
              "       [ 31],\n",
              "       [ 64],\n",
              "       [ 81],\n",
              "       [ 63],\n",
              "       [  6],\n",
              "       [ 11],\n",
              "       [ 32],\n",
              "       [ 35],\n",
              "       [ 84],\n",
              "       [  1],\n",
              "       [ 23],\n",
              "       [ 43],\n",
              "       [ 15],\n",
              "       [ 23],\n",
              "       [ 56],\n",
              "       [ 70],\n",
              "       [ 70],\n",
              "       [ 13],\n",
              "       [ 50],\n",
              "       [ 26],\n",
              "       [ 53]])>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "zmEA4rjPJp_Z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irxC5IZRJs0S",
        "outputId": "860fd00c-58dc-4044-cbef-4b4e716891c0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([100,  84,  90,   8,  84,  69,  43,  25,   4,  79,  31,  15,  18,\n",
              "        99,  61,  34,  94,  91,  76,  98,  39,  56,  83,  97,  36,  58,\n",
              "       101,  40,  53,  66,   1,   1,  42,  88,  25,  60,  78,  26,  94,\n",
              "        96,  29,  38,  31,  51,   0,  70,  55,  95,  66,  46,  45, 101,\n",
              "        46,  72,   4,   8,  90,  94,  69,  69,  13,  91,  23,  24,   3,\n",
              "        49,   4,  28,  56,   0,  27,  41,  75,  63,  15,   5,   3,  93,\n",
              "        97,  74,  12,  83,  42,  44,  99,  53,  82,  18,   3,  86,  99,\n",
              "        78, 102,  92,  97,  12,  71,  92,  47,  59,  33,  12,  90,  11,\n",
              "         2,  23,  62,   8,  38,  32,  10, 101,  86,  47,  49,   6,  70,\n",
              "        68,  25,  38,  21,  37,   0,  90,  24,  88,  68,  87,  82,  86,\n",
              "        70,  98,  30,  68,  28,  19,  83,  11,  67,  56,  70,  33,  33,\n",
              "        60,  91,  42,  37,  43,  59,  10,  11,  78,  13,   4,   6,  82,\n",
              "         1,  21,  41,  48,  78,  39,  69,  22,  18,  36,  58,  93,  45,\n",
              "        91,  48,  52,  99,  49,  89,  39,  75,  22,  57,  31,  64,  81,\n",
              "        63,   6,  11,  32,  35,  84,   1,  23,  43,  15,  23,  56,  70,\n",
              "        70,  13,  50,  26,  53])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "-66I5t9uJuYi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szKZpxtUJwgS",
        "outputId": "c2d12f78-f0cd-45c6-fe37-179e06cc6302"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "92/92 [==============================] - 29s 224ms/step - loss: 3.1807\n",
            "Epoch 2/30\n",
            "92/92 [==============================] - 25s 222ms/step - loss: 2.4135\n",
            "Epoch 3/30\n",
            "92/92 [==============================] - 25s 232ms/step - loss: 2.2217\n",
            "Epoch 4/30\n",
            "92/92 [==============================] - 25s 232ms/step - loss: 2.0363\n",
            "Epoch 5/30\n",
            "92/92 [==============================] - 25s 233ms/step - loss: 1.8692\n",
            "Epoch 6/30\n",
            "92/92 [==============================] - 25s 233ms/step - loss: 1.7267\n",
            "Epoch 7/30\n",
            "92/92 [==============================] - 24s 228ms/step - loss: 1.6112\n",
            "Epoch 8/30\n",
            "92/92 [==============================] - 26s 241ms/step - loss: 1.5237\n",
            "Epoch 9/30\n",
            "92/92 [==============================] - 25s 230ms/step - loss: 1.4587\n",
            "Epoch 10/30\n",
            "92/92 [==============================] - 25s 226ms/step - loss: 1.4082\n",
            "Epoch 11/30\n",
            "92/92 [==============================] - 25s 239ms/step - loss: 1.3692\n",
            "Epoch 12/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.3353\n",
            "Epoch 13/30\n",
            "92/92 [==============================] - 25s 234ms/step - loss: 1.3077\n",
            "Epoch 14/30\n",
            "92/92 [==============================] - 25s 229ms/step - loss: 1.2820\n",
            "Epoch 15/30\n",
            "92/92 [==============================] - 25s 238ms/step - loss: 1.2606\n",
            "Epoch 16/30\n",
            "92/92 [==============================] - 25s 232ms/step - loss: 1.2428\n",
            "Epoch 17/30\n",
            "92/92 [==============================] - 24s 226ms/step - loss: 1.2225\n",
            "Epoch 18/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.2049\n",
            "Epoch 19/30\n",
            "92/92 [==============================] - 25s 236ms/step - loss: 1.1895\n",
            "Epoch 20/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.1738\n",
            "Epoch 21/30\n",
            "92/92 [==============================] - 24s 226ms/step - loss: 1.1587\n",
            "Epoch 22/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.1428\n",
            "Epoch 23/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.1275\n",
            "Epoch 24/30\n",
            "92/92 [==============================] - 25s 229ms/step - loss: 1.1118\n",
            "Epoch 25/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.0984\n",
            "Epoch 26/30\n",
            "92/92 [==============================] - 25s 231ms/step - loss: 1.0841\n",
            "Epoch 27/30\n",
            "92/92 [==============================] - 26s 235ms/step - loss: 1.0674\n",
            "Epoch 28/30\n",
            "92/92 [==============================] - 25s 232ms/step - loss: 1.0522\n",
            "Epoch 29/30\n",
            "92/92 [==============================] - 25s 233ms/step - loss: 1.0379\n",
            "Epoch 30/30\n",
            "92/92 [==============================] - 25s 235ms/step - loss: 1.0211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae96b75f30>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('EM.Forst.h5')"
      ],
      "metadata": {
        "id": "okDtGwLIKkiX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "jUI0mDAmLO1D"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights('EM.Forst.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n"
      ],
      "metadata": {
        "id": "uBESV-DaLSw6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckVx5ddfLkcQ",
        "outputId": "2853005e-2f25-46ec-c9bb-930be6f0680a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 64)             6592      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 103)            105781    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,473,549\n",
            "Trainable params: 3,473,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        "\n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "hbqaJ8wILowu"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"When she was\",gen_size=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WvE_pdXLruv",
        "outputId": "4ac8a8d3-dc86-4c93-dc2e-2b2be5ab1b6b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When she was voice, and minded what he said to Mr. Honeychurch right—kindly, and to hear the funires\n",
            "flood, the \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0aJLKsZLvA_"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}